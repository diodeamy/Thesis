# Week 9 ugh

I changed in "gadget_reader_HDF5.cc" in line 209 from DataSet dataset = group->openDataSet("Velocity"); DataSet dataset = group->openDataSet("Velocities");, also in line 565 as well as in file hdf5_input_my_DESI.cc in line 236

## the DTFE make output is

g++ -frounding-math -O3 -fopenmp -DNDEBUG  -DNO_DIM=3  -DVELOCITY  -DSCALAR  -DNO_SCALARS=1  -DINPUT_FILE_DEFAULT=101  -DMPC_UNIT=1000.  -DOUTPUT_FILE_DEFAULT=101   -DOPEN_MP  -DREDSHIFT_SPACE -DFIELD_OPTIONS  -DREGION_OPTIONS  -DAVERAGING_OPTIONS  -DADDITIONAL_OPTIONS  -DHDF5  -I//cosma/local/gsl/2.4/include  -I//cosma/local/boost/gnu_7.3.0/1_67_0/include  -I//Users/users/nastase/Libraries/include  -I//cosma/local/hdf5/gnu_7.3.0/1.10.3/include  -o ./o/DTFE.o -c ./src/DTFE.cpp
g++ -frounding-math -O3 -fopenmp -DNDEBUG  -DNO_DIM=3  -DVELOCITY  -DSCALAR  -DNO_SCALARS=1  -DINPUT_FILE_DEFAULT=101  -DMPC_UNIT=1000.  -DOUTPUT_FILE_DEFAULT=101   -DOPEN_MP  -DREDSHIFT_SPACE -DFIELD_OPTIONS  -DREGION_OPTIONS  -DAVERAGING_OPTIONS  -DADDITIONAL_OPTIONS  -DHDF5  -I//cosma/local/gsl/2.4/include  -I//cosma/local/boost/gnu_7.3.0/1_67_0/include  -I//Users/users/nastase/Libraries/include  -I//cosma/local/hdf5/gnu_7.3.0/1.10.3/include  -o ./o/triangulation.o -c ./src/CGAL_triangulation/triangulation.cpp
g++ -frounding-math -O3 -fopenmp -DNDEBUG  -DNO_DIM=3  -DVELOCITY  -DSCALAR  -DNO_SCALARS=1  -DINPUT_FILE_DEFAULT=101  -DMPC_UNIT=1000.  -DOUTPUT_FILE_DEFAULT=101   -DOPEN_MP  -DREDSHIFT_SPACE -DFIELD_OPTIONS  -DREGION_OPTIONS  -DAVERAGING_OPTIONS  -DADDITIONAL_OPTIONS  -DHDF5  -I//cosma/local/gsl/2.4/include  -I//cosma/local/boost/gnu_7.3.0/1_67_0/include  -I//Users/users/nastase/Libraries/include  -I//cosma/local/hdf5/gnu_7.3.0/1.10.3/include  -o ./o/main.o -c ./src/main.cpp
g++ -O3 -ffast-math -fomit-frame-pointer  -I//cosma/local/gsl/2.4/include  -I//cosma/local/boost/gnu_7.3.0/1_67_0/include-I//Users/users/nastase/Libraries/include  -I//cosma/local/hdf5/gnu_7.3.0/1.10.3/include  -o ./o/kdtree2.o -c ./src/kdtree/kdtree2.cpp
g++ -frounding-math -O3 -fopenmp -DNDEBUG  -DNO_DIM=3  -DVELOCITY  -DSCALAR  -DNO_SCALARS=1  -DINPUT_FILE_DEFAULT=101  -DMPC_UNIT=1000.  -DOUTPUT_FILE_DEFAULT=101   -DOPEN_MP  -DREDSHIFT_SPACE -DFIELD_OPTIONS  -DREGION_OPTIONS  -DAVERAGING_OPTIONS  -DADDITIONAL_OPTIONS  -DHDF5 ./o/DTFE.o ./o/triangulation.o ./o/main.o ./o/kdtree2.o  -L//cosma/local/gsl/2.4/lib  -L//cosma/local/boost/gnu_7.3.0/1_67_0/lib  -L//Users/users/nastase/Libraries/lib  -L//cosma/local/hdf5/gnu_7.3.0/1.10.3/lib -lhdf5 -lhdf5_cpp -lCGAL -lboost_thread -lboost_filesystem -lboost_program_options -lgsl -lgslcblas -lm  -lgmp -lmpfr -lboost_system -o .//DTFE

## the problem

The scipy.weave module is deprecated. It was the only module never ported to Python 3.x, and is not recommended to be used for new code - use Cython instead. In order to support existing code, scipy.weave has been packaged separately: scipy/weave. It is a pure Python package, and can easily be installed with pip install weave.

## weave package that has experimental python 3.x

<https://github.com/scipy/weave>

## another possible solution

Here is mentioned that : Weave is the stand-alone version of the deprecated Scipy submodule scipy.weave.

Solution: I removed the package, replaced the scipy.weave by weave in files and reinstalled by setup.py file. that's all.

## Ivan's words of wisdom

wehn you import nexus mmf clean stuff it becomes a mask; you can multiply your data by that, use it as a mask, if you scale the data to the 256 box,

## Parsing Tool errors for NEXUS app when running 2to3

RefactoringTool: Can't parse ./bin/AHF.py: ParseError: bad input: type=22, value='=', context=('', (215, 110))
RefactoringTool: Can't parse ./bin/MMF.py: ParseError: bad input: type=22, value='=', context=('', (236, 84))
RefactoringTool: Can't parse ./bin/density.py: ParseError: bad input: type=22, value='=', context=('', (200, 90))
RefactoringTool: Can't parse ./bin/density_toVisit.py: ParseError: bad input: type=22, value='=', context=('', (19, 33))
RefactoringTool: Can't parse ./bin/gadget.py: ParseError: bad input: type=22, value='=', context=('', (429, 81))
RefactoringTool: Can't parse ./bin/halo.py: ParseError: bad input: type=22, value='=', context=('', (143, 94))
RefactoringTool: Can't parse ./bin/miscellaneous.py: ParseError: bad input: type=22, value='=', context=('', (62, 43))
RefactoringTool: Can't parse ./bin/silo.py: ParseError: bad input: type=22, value='=', context=('', (26, 77))
RefactoringTool: Can't parse ./bin/textFile.py: ParseError: bad input: type=22, value='=', context=('', (16, 82))
RefactoringTool: Can't parse ./python/density_downsampleGrid.py: ParseError: bad input: type=22, value='=', context=('', (68, 110))
RefactoringTool: Can't parse ./python/density_toVisit.py: ParseError: bad input: type=22, value='=', context=('', (19, 33))
RefactoringTool: Can't parse ./python/halo_getAHFData.py: ParseError: bad input: type=22, value='=', context=('', (49, 149))
RefactoringTool: Can't parse ./python/readBinary.py: ParseError: bad input: type=22, value='=', context=('', (18, 45))
RefactoringTool: Can't parse ./python/python_import/AHF.py: ParseError: bad input: type=22, value='=', context=('', (215, 110))
RefactoringTool: Can't parse ./python/python_import/density.py: ParseError: bad input: type=22, value='=', context=('', (200, 88))
RefactoringTool: Can't parse ./python/python_import/gadget.py: ParseError: bad input: type=22, value='=', context=('', (429, 81))
RefactoringTool: Can't parse ./python/python_import/halo.py: ParseError: bad input: type=22, value='=', context=('', (143,94))
RefactoringTool: Can't parse ./python/python_import/miscellaneous.py: ParseError: bad input: type=22, value='=', context=('', (62, 43))
RefactoringTool: Can't parse ./python/python_import/silo.py: ParseError: bad input: type=22, value='=', context=('', (26, 77))
RefactoringTool: Can't parse ./python/python_import/textFile.py: ParseError: bad input: type=22, value='=', context=('', (16, 82))

## The workflow

- ran Calin's script to transform .hdf5 files to .gadget

- saved all the gadget files to PROJECT/DATA/gadgets/

- then we run DTFE on them and save the resulting field(s) to PROJECT/DATA/gadget_dtfe/

- the python_with_NEXUS notebook provided with the package was copyied into a directory PROJECT/DATA/nexus_outputs/MMF_results to make it easier to run (it saves things locally and I was too lazy to change path names everywhere)
