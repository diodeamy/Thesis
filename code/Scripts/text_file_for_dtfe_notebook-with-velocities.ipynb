{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b49e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import illustris_python as il\n",
    "import numpy as np\n",
    "import sys\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from shared.utilities import get_redshift_dictionary\n",
    "\n",
    "base_path = \"/Users/users/nastase/PROJECT/\"\n",
    "output_path = \"/Users/users/nastase/PROJECT/DATA/files_for_dtfe/\"\n",
    "\n",
    "def load_data(snapshot_number):\n",
    "    data = il.snapshot.loadSubset(base_path, snapshot_number, 'dm', [\"Coordinates\", \"Velocities\", \"ParticleIDs\"])\n",
    "    data[\"Masses\"] = np.ones(len(data[\"Coordinates\"]))\n",
    "\n",
    "    \n",
    "    return data\n",
    "\n",
    "def process_snapshot(snapshot_number):\n",
    "    print(f\"Start processing {snapshot_number}\")\n",
    "    data = load_data(snapshot_number)\n",
    "    convert_data_to_tex_even_faster(data, snapshot_number, output_path)\n",
    "    \n",
    "    print(f\"Finish processing {snapshot_number}\")\n",
    "\n",
    "def convert_data_to_tex_even_faster(data, snapshot_number, path):\n",
    "    \n",
    "    particle_number = data[\"count\"]\n",
    "    coordinates = data[\"Coordinates\"]\n",
    "    celovities = data[\"Velocities\"]\n",
    "    particleIDs = data[\"PaticleIDs\"]\n",
    "    masses = data[\"Masses\"]\n",
    "    \n",
    "    box_min = 0\n",
    "    box_max = 75000\n",
    "    \n",
    "    filename = f\"{path}/file_vel_ids_{snapshot_number}.txt\"\n",
    "    header = f\"{particle_number}\\n{box_min:.6f} {box_max:.6f} {box_min:.6f} {box_max:.6f} {box_min:.6f} {box_max:.6f}\\n\"\n",
    "    all_data = np.hstack((coordinates, velocities,masses.reshape(-1, 1), particleIDs))\n",
    "\n",
    "    \n",
    "    # Convert all data to formatted strings\n",
    "    lines = \"\\n\".join(f\"{x:.6f} {y:.6f} {z:.6f} {vx:.6f} {vy:.6f} {vz:.6f} {m:.6f} {ids:.6f}\" for x, y, z, vx, vy, vz, m, ids in all_data ) \n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(header)\n",
    "        f.write(lines)\n",
    "        f.write('\\n')  # Add a newline at the end     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16f9caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[135,\n",
       " 133,\n",
       " 131,\n",
       " 129,\n",
       " 127,\n",
       " 125,\n",
       " 123,\n",
       " 122,\n",
       " 118,\n",
       " 114,\n",
       " 110,\n",
       " 106,\n",
       " 102,\n",
       " 98,\n",
       " 94,\n",
       " 90,\n",
       " 86,\n",
       " 82,\n",
       " 78,\n",
       " 74,\n",
       " 70,\n",
       " 66,\n",
       " 64,\n",
       " 62,\n",
       " 60,\n",
       " 58,\n",
       " 56,\n",
       " 54,\n",
       " 53,\n",
       " 51,\n",
       " 49]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     dictionary = get_redshift_dictionary()\n",
    "#     dictionary['snapshots']\n",
    "#     snapshot_numbers = [49, 58, 70, 82, 94, 110, 122]\n",
    "\n",
    "#     ##this is for more I/O bound tasks    \n",
    "#     with ThreadPoolExecutor() as executor:\n",
    "#         executor.map(process_snapshot, snapshot_numbers)\n",
    "    \n",
    "    #this is for more other (MY KIND) kinds of tasks? \n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        executor.map(process_snapshot, snapshot_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac5ace0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 94196375,\n",
       " 'Coordinates': array([[  860.2786  , 26320.94    , 18281.758   ],\n",
       "        [  862.8968  , 26320.16    , 18283.193   ],\n",
       "        [  859.6459  , 26324.168   , 18280.25    ],\n",
       "        ...,\n",
       "        [60536.855   , 49059.383   , 56893.633   ],\n",
       "        [65776.43    , 61606.74    , 46854.918   ],\n",
       "        [64010.445   , 61434.027   ,    70.096725]], dtype=float32),\n",
       " 'Velocities': array([[  37.119167, -126.95646 , -137.56683 ],\n",
       "        [ -62.20938 , -280.38562 , -148.18048 ],\n",
       "        [  79.16669 , -229.4381  ,  -60.910133],\n",
       "        ...,\n",
       "        [  88.98358 ,  148.74493 , -175.3597  ],\n",
       "        [ 242.84515 ,   16.739655,  113.39123 ],\n",
       "        [ 174.96793 ,   17.906925,   -8.918241]], dtype=float32),\n",
       " 'ParticleIDs': array([88038007, 88173007,  3638407, ..., 94196369, 94196373, 94196375],\n",
       "       dtype=uint64),\n",
       " 'Masses': array([1., 1., 1., ..., 1., 1., 1.])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data(135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6081088e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3 - 2023.03",
   "language": "python",
   "name": "python3-2023.03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
