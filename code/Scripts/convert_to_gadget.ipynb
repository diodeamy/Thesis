{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9be87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import sys\n",
    "import numpy as np \n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b36674",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"/Users/users/nastase/PROJECT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f9de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importFiles(timestep, path=basepath):\n",
    "    c_coordinates = None\n",
    "    c_velocities = None\n",
    "    c_ids = None\n",
    "    snapshot_dir_path = f\"{basepath}/snapdir_{timestep}\"\n",
    "    for file in os.listdir(snapshot_dir_path):\n",
    "        if 'hdf5' in file:\n",
    "            print(f\"Processing file: {file}\")\n",
    "            coordinates = h5py.File(f\"{snapshot_dir_path}/{file}\", 'r')['PartType1']['Coordinates'][:]\n",
    "            velocities = h5py.File(f\"{snapshot_dir_path}/{file}\", 'r')['PartType1']['Velocities'][:]\n",
    "            ids = h5py.File(f\"{snapshot_dir_path}/{file}\", 'r')['PartType1']['ParticleIDs'][:]\n",
    "            if c_coordinates is None:\n",
    "                c_coordinates = coordinates \n",
    "            if c_velocities is None:\n",
    "                c_velocities = velocities \n",
    "            if c_ids is None:\n",
    "                c_ids = ids \n",
    "            else:\n",
    "                c_coordinates = np.concatenate((c_coordinates, coordinates), axis = 0)\n",
    "                c_velocities = np.concatenate((c_velocities, velocities), axis = 0)\n",
    "                c_ids = np.concatenate((c_ids, ids), axis = 0)\n",
    "        \n",
    "    c_coordinates = c_coordinates/75000 * 256 # changing the scale to Mpc/h\n",
    "    c_coordiantes = c_coordinates.astype(np.float32)\n",
    "    print(len(c_coordinates), len( c_velocities), len(c_ids))\n",
    "    return c_coordinates, c_velocities, c_ids\n",
    "\n",
    "def order_ids(pos, vel, ids):\n",
    "    # Ensure ids are zero-indexed for proper array indexing\n",
    "    ids = ids - 1\n",
    "\n",
    "    # Create arrays for ordered positions, velocities, and ids\n",
    "    ord_pos = np.zeros(np.shape(pos), dtype=pos.dtype)\n",
    "    ord_vel = np.zeros(np.shape(vel), dtype=vel.dtype)\n",
    "\n",
    "    # Use the ids as indices to order the arrays\n",
    "    ord_pos[ids] = pos\n",
    "    ord_vel[ids] = vel\n",
    "\n",
    "    # Create the ordered ids array\n",
    "    ord_ids = np.arange(1, len(ids) + 1, dtype=np.uint32)\n",
    "\n",
    "    return ord_pos, ord_vel, ord_ids\n",
    "\n",
    "def random_downsample(pos, vel, downsample_fraction):\n",
    "    array = np.random.rand(len(pos)) < downsample_fraction \n",
    "    pos = pos[array]\n",
    "    vel = vel[array]\n",
    "    ids = np.arange(1, len(pos) + 1, dtype=np.uint32)\n",
    "    return pos, vel, ids\n",
    "\n",
    "def downsample(pos, vel, downsample_factor):\n",
    "    ds_ord_pos = pos[::downsample_factor]\n",
    "    ds_ord_vel = vel[::downsample_factor]\n",
    "    ds_ord_ids = np.arange(1, len(ds_ord_pos) + 1, dtype=np.uint32)\n",
    "    \n",
    "    print('Checking the lengths of the arrays:')\n",
    "    print('Positions: ', len(ds_ord_pos))\n",
    "    print('Velocities: ', len(ds_ord_vel))\n",
    "    print('IDs: ', len(ds_ord_ids))\n",
    "    \n",
    "    return ds_ord_pos, ds_ord_vel, ds_ord_ids\n",
    "\n",
    "# Write the Gadget-1 file with Fortran-style record markers\n",
    "def write_gadget(header, ds_coordinates, ds_velocities, ds_ids, name):\n",
    "    \n",
    "    def write_fortran_record(f, data):\n",
    "        record_size = len(data)\n",
    "        f.write(struct.pack('i', record_size))\n",
    "        f.write(data)\n",
    "        f.write(struct.pack('i', record_size))\n",
    "    \n",
    "    path = \"/Users/users/nastase/PROJECT/DATA/gadgets\"\n",
    "    with open(f\"{path}/snapshot_{name}.gadget\", 'wb') as f:\n",
    "        # Write the header\n",
    "        write_fortran_record(f, header.tobytes())\n",
    "    \n",
    "        # Write the particle positions\n",
    "        write_fortran_record(f, ds_coordinates.tobytes())\n",
    "    \n",
    "        # Write the particle velocities\n",
    "        write_fortran_record(f, ds_velocities.tobytes())\n",
    "    \n",
    "        # Write the particle IDs\n",
    "        write_fortran_record(f, ds_ids.tobytes())\n",
    "\n",
    "    print(f\"Gadget-1 file 'snap_{name}.gadget' created with Fortran-style record markers, saved in {path}\")\n",
    "    \n",
    "def normalizeCoords(coords, ngpt):\n",
    "    cmax = np.max(coords)\n",
    "    cmin = np.min(coords)\n",
    "    coords = (coords - cmin)/(cmax-cmin) * ngpt\n",
    "    return coords\n",
    "    \n",
    "def testPlot(x, y):\n",
    "    plt.scatter(x, y, marker = \"o\", s = 0.1, alpha = 0.5)\n",
    "    plt.show()\n",
    "    print(\"test plot completed\")\n",
    "\n",
    "# Define header values\n",
    "# Downsampling the simulation files to make it easier for computation\n",
    "def something_else(timesteps):\n",
    "# #     if len(sys.argv) < 2:\n",
    "#         print(\"Usage: python conver_to_gadget.py timestep1 timestep2 ...\")\n",
    "#         sys.exit(1)\n",
    "    for step in timesteps:\n",
    "        header_dtype = np.dtype([\n",
    "            ('npart', (np.int32, 6)),         # Number of particles of each type\n",
    "            ('mass', (np.float64, 6)),        # Mass of each particle type\n",
    "            ('time', np.float64),             # Time of the snapshot\n",
    "            ('redshift', np.float64),         # Redshift of the snapshot\n",
    "            ('flag_sfr', np.int32),           # Star formation flag\n",
    "            ('flag_feedback', np.int32),      # Feedback flag\n",
    "            ('npartTotal', (np.int32, 6)),    # Total number of particles of each type\n",
    "            ('flag_cooling', np.int32),       # Cooling flag\n",
    "            ('num_files', np.int32),          # Number of files in multi-file set\n",
    "            ('BoxSize', np.float64),          # Box size of the simulation\n",
    "            ('Omega0', np.float64),           # Matter density parameter\n",
    "            ('OmegaLambda', np.float64),      # Cosmological constant density parameter\n",
    "            ('HubbleParam', np.float64),      # Hubble parameter\n",
    "            ('flag_stellarage', np.int32),    # Stellar age flag\n",
    "            ('flag_metals', np.int32),        # Metals flag\n",
    "            ('npartTotalHighWord', (np.int32, 6)),  # High word of total number of particles\n",
    "            ('flag_entropy_instead_u', np.int32),   # Entropy flag\n",
    "            ('flag_doubleprecision', np.int32),     # Double precision flag\n",
    "            ('flag_ic_info', np.int32),             # IC info flag\n",
    "            ('lpt_scalingfactor', np.float32),      # LPT scaling factor\n",
    "            ('fill', (np.int32, 12))          # Padding to make header 256 bytes\n",
    "        ])\n",
    "\n",
    "\n",
    "        pos, vel, ids = importFiles(step)\n",
    "        print(f\"Converting timestep {step}\")\n",
    "        ord_pos, ord_vel, ord_ids = order_ids(pos, vel, ids)\n",
    "    \n",
    "#         rand_pos, rand_vel, ids = random_downsample(ord_pos, ord_vel, 0.1)\n",
    "#         rand_pos = rand_pos.astype(np.float32)\n",
    "#         rand_vel = rand_vel.astype(np.float32)\n",
    "#         m = np.ones(len(rand_pos))\n",
    "        m = np.ones(len(ord_pos))\n",
    "\n",
    "           \n",
    "        # Initialize the header with example values\n",
    "        header = np.zeros(1, dtype=header_dtype)\n",
    "        header['npart'] = [0,len(ord_pos), 0, 0, 0, 0]\n",
    "        header['mass'] = [0.0, 0.03388571, 0.0, 0.0, 0.0, 0.0]\n",
    "        header['time'] = 0.9999999999999998\n",
    "        header['redshift'] = 2.220446049250313e-16\n",
    "        header['flag_sfr'] = 0\n",
    "        header['flag_feedback'] = 0\n",
    "        header['npartTotal'] = [0, len(ord_pos), 0, 0, 0, 0] #was 94196375\n",
    "        header['flag_cooling'] = 0\n",
    "        header['num_files'] = 8 #was 8\n",
    "        header['BoxSize'] = 256.0  # Ensuring it's a large enough box\n",
    "        header['Omega0'] = 0.2726\n",
    "        header['OmegaLambda'] = 0.7274\n",
    "        header['HubbleParam'] = 0.704\n",
    "        header['flag_stellarage'] = 0\n",
    "        header['flag_metals'] = 0\n",
    "        header['npartTotalHighWord'] = [0, 0, 0, 0, 0, 0]\n",
    "        header['flag_entropy_instead_u'] = 0\n",
    "        header['flag_doubleprecision'] = 0\n",
    "        header['flag_ic_info'] = 0\n",
    "        header['lpt_scalingfactor'] = 1.0\n",
    "        header['fill'] = [0] * 12\n",
    "\n",
    "\n",
    "\n",
    "        write_gadget(header, ord_pos, ord_vel, ord_ids, step)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "# \tmain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e5c3e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: snap_135.7.hdf5\n",
      "Processing file: snap_135.3.hdf5\n",
      "Processing file: snap_135.6.hdf5\n",
      "Processing file: snap_135.2.hdf5\n",
      "Processing file: snap_135.4.hdf5\n",
      "Processing file: snap_135.0.hdf5\n",
      "Processing file: snap_135.5.hdf5\n",
      "Processing file: snap_135.1.hdf5\n",
      "94196375 94196375 94196375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[44327.023, 39605.055, 38644.78 ],\n",
       "        [42850.305, 38274.6  , 56301.95 ],\n",
       "        [50704.21 , 57091.812, 29159.74 ],\n",
       "        ...,\n",
       "        [41256.246,  8804.057, 62842.65 ],\n",
       "        [41160.574,  8751.447, 63042.54 ],\n",
       "        [41267.6  ,  8942.503, 63163.703]], dtype=float32),\n",
       " array([[-181.18648 ,  -38.86602 ,   10.873716],\n",
       "        [-338.7867  ,  -29.603165,  159.50095 ],\n",
       "        [ -75.49441 ,  194.70346 ,  -26.610498],\n",
       "        ...,\n",
       "        [ 202.07915 ,  -33.010574, -201.70589 ],\n",
       "        [-454.50214 , -109.31646 ,   55.418056],\n",
       "        [ -17.90345 ,  122.45168 ,   69.63247 ]], dtype=float32),\n",
       " array([71805538, 71805539, 71805542, ..., 43859755, 59444355, 59454780],\n",
       "       dtype=uint64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importFiles(135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebfbf9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: snap_135.7.hdf5\n",
      "Processing file: snap_135.3.hdf5\n",
      "Processing file: snap_135.6.hdf5\n",
      "Processing file: snap_135.2.hdf5\n",
      "Processing file: snap_135.4.hdf5\n",
      "Processing file: snap_135.0.hdf5\n",
      "Processing file: snap_135.5.hdf5\n",
      "Processing file: snap_135.1.hdf5\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(f\"{basepath}/snapdir_{timestep}\"):\n",
    "    if 'hdf5' in file:\n",
    "        print(f\"Processing file: {file}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efad6dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: snap_135.7.hdf5\n",
      "Processing file: snap_135.3.hdf5\n",
      "Processing file: snap_135.6.hdf5\n",
      "Processing file: snap_135.2.hdf5\n",
      "Processing file: snap_135.4.hdf5\n",
      "Processing file: snap_135.0.hdf5\n",
      "Processing file: snap_135.5.hdf5\n",
      "Processing file: snap_135.1.hdf5\n",
      "94196375 94196375 94196375\n",
      "Converting timestep 135\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "'i' format requires -2147483648 <= number <= 2147483647",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msomething_else\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m135\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 169\u001b[0m, in \u001b[0;36msomething_else\u001b[0;34m(timesteps)\u001b[0m\n\u001b[1;32m    164\u001b[0m header[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlpt_scalingfactor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    165\u001b[0m header[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[0;32m--> 169\u001b[0m \u001b[43mwrite_gadget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mord_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mord_vel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mord_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 79\u001b[0m, in \u001b[0;36mwrite_gadget\u001b[0;34m(header, ds_coordinates, ds_velocities, ds_ids, name)\u001b[0m\n\u001b[1;32m     76\u001b[0m write_fortran_record(f, header\u001b[38;5;241m.\u001b[39mtobytes())\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Write the particle positions\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m \u001b[43mwrite_fortran_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_coordinates\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Write the particle velocities\u001b[39;00m\n\u001b[1;32m     82\u001b[0m write_fortran_record(f, ds_velocities\u001b[38;5;241m.\u001b[39mtobytes())\n",
      "Cell \u001b[0;32mIn[6], line 69\u001b[0m, in \u001b[0;36mwrite_gadget.<locals>.write_fortran_record\u001b[0;34m(f, data)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_fortran_record\u001b[39m(f, data):\n\u001b[1;32m     68\u001b[0m     record_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[0;32m---> 69\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[43mstruct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord_size\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     70\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[1;32m     71\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m, record_size))\n",
      "\u001b[0;31merror\u001b[0m: 'i' format requires -2147483648 <= number <= 2147483647"
     ]
    }
   ],
   "source": [
    "something_else([135])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d4ef9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3 - 2023.03",
   "language": "python",
   "name": "python3-2023.03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
