{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53bbb899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import illustris_python as il\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceee65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/Users/users/nastase/PROJECT/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94cbb8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(snapshot_number):\n",
    "    data = il.snapshot.loadSubset(base_path, snapshot_number, 'dm', [\"Coordinates\", \"Velocities\"])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04ef6364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_subset(data, fraction):\n",
    "    N_el = len(data[\"Coordinates\"])\n",
    "    random = np.random.uniform(0, 1, N_el)\n",
    "    mask = random < fraction\n",
    "    \n",
    "    # Apply the mask to the coordinates and velocities\n",
    "    coordinates_small = data[\"Coordinates\"][mask]\n",
    "    velocities_small = data[\"Velocities\"][mask]\n",
    "    \n",
    "    # Create the new data dictionary with the masked data\n",
    "    data_small = {\n",
    "        \"count\": np.sum(mask),  # This is the number of elements in the small subset\n",
    "        \"Coordinates\": coordinates_small,\n",
    "        \"Velocities\": velocities_small\n",
    "    }\n",
    "    \n",
    "    return data_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf4ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3672b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_small = create_data_subset(data, 1/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94f8db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_data_to_text(data, snapshot_number, path):\n",
    "    \n",
    "#     particle_number = data[\"count\"]\n",
    "#     coordinates = data[\"Coordinates\"]\n",
    "#     velocities = data[\"Velocities\"]\n",
    "    \n",
    "#     box_min = 0\n",
    "#     box_max = 75000\n",
    "    \n",
    "#     filename = f\"{path}_{snapshot_number}.txt\"\n",
    "#     with open(filename, 'w') as f:\n",
    "#         f.write(f\"{particle_number}\\n\")\n",
    "#         f.write(f\"{box_min:.6f} {box_max:.6f} {box_min:.6f} {box_max:.6f} {box_min:.6f} {box_max:.6f}\\n\")\n",
    "        \n",
    "#         for i in range(particle_number):\n",
    "#             x, y, z = coordinates[i]\n",
    "#             vx, vy, vz = velocities[i]\n",
    "            \n",
    "#             f.write(f\"{x:.6f} {y:.6f} {z:.6f} {vx:.6f} {vy:.6f} {vz:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42aa0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_data_to_text_fast(data, snapshot_number, path):\n",
    "    \n",
    "#     particle_number = data[\"count\"]\n",
    "#     coordinates = data[\"Coordinates\"]\n",
    "#     velocities = data[\"Velocities\"]\n",
    "    \n",
    "#     box_min = 0\n",
    "#     box_max = 75000\n",
    "    \n",
    "#     filename = f\"{path}_{snapshot_number}.txt\"\n",
    "#     header = f\"{particle_number}\\n{box_min:.6f} {box_max:.6f} {box_min:.6f} {box_max:.6f} {box_min:.6f} {box_max:.6f}\\n\"\n",
    "    \n",
    "#     lines = []\n",
    "#     for i in range(particle_number):\n",
    "#         x, y, z = coordinates[i]\n",
    "#         vx, vy, vz = velocities[i]\n",
    "#         lines.append(f\"{x:.6f} {y:.6f} {z:.6f} {vx:.6f} {vy:.6f} {vz:.6f}\\n\")\n",
    "    \n",
    "#     with open(filename, 'w') as f:\n",
    "#         f.write(header)\n",
    "#         f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "915d01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_tex_even_faster(data, snapshot_number, path):\n",
    "    \n",
    "    particle_number = data[\"count\"]\n",
    "    coordinates = data[\"Coordinates\"]\n",
    "    velocities = data[\"Velocities\"]\n",
    "    \n",
    "    box_min = 0\n",
    "    box_max = 75000\n",
    "    \n",
    "    filename = f\"{path}/file_{snapshot_number}.txt\"\n",
    "    header = f\"{particle_number}\\n{box_min:.6f} {box_max:.6f} {box_min:.6f} {box_max:.6f} {box_min:.6f} {box_max:.6f}\\n\"\n",
    "    \n",
    "    all_data = np.hstack((coordinates, velocities))\n",
    "    \n",
    "    # Convert all data to formatted strings\n",
    "    lines = \"\\n\".join(f\"{x:.6f} {y:.6f} {z:.6f} {vx:.6f} {vy:.6f} {vz:.6f}\" for x, y, z, vx, vy, vz in all_data)\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(header)\n",
    "        f.write(lines)\n",
    "        f.write('\\n')  # Add a newline at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abe783d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_data_to_tex_even_faster(data_small, 135, \"/Users/users/nastase/PROJECT/DATA/files_for_dtfe/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615df18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Anaconda3 - 2023.03",
   "language": "python",
   "name": "python3-2023.03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
